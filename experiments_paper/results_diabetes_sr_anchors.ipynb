{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8177c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from acv_explainers import ACXplainer\n",
    "from acv_explainers.utils import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import DatasetHelper, DATASETS_NAME\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b167d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_model('/home/xxxxxx/cet_rei2/DiabetesFCR_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295cdc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sr_results(x_test, rules, x_rules, y_rules, s_star, predict):\n",
    "    N = rules.shape[0]\n",
    "    d = rules.shape[1]\n",
    "    \n",
    "    coverages = []\n",
    "    accuracies = []\n",
    "    supports = []\n",
    "    for idx in tqdm(range(N)):\n",
    "        x_in = np.prod([(x_test[:, s] <= rules[idx, s, 1]) * (x_test[:, s] > rules[idx, s, 0])\n",
    "                        for s in range(d)], axis=0).astype(bool)\n",
    "        \n",
    "        if  np.sum(x_in) == 0:\n",
    "            continue\n",
    "            \n",
    "        coverage = np.mean(x_in)\n",
    "        accuracy = np.mean(predict(x_test[x_in]) == y_rules[idx].reshape(1, -1))\n",
    "        \n",
    "        coverages.append(coverage)\n",
    "        accuracies.append(accuracy)\n",
    "        supports.append(len(s_star[idx]))\n",
    "        \n",
    "    return coverages, accuracies, supports, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4216d568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:01<00:00, 995.35it/s]\n"
     ]
    }
   ],
   "source": [
    "coverages_sr, accuracies_sr, supports_sr, rules_sr = get_sr_results(results.x_test, results.rules, results.x_rules, results.y_rules,\n",
    "                                                                        results.S_star_se, results.acv_explainer.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc73090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR: Coverage = 0.01987544483985765 - Accuracy = 0.7046083333333334 - Support = 1.294\n"
     ]
    }
   ],
   "source": [
    "N = results.rules.shape[0]\n",
    "print('SR: Coverage = {} - Accuracy = {} - Support = {}'.format(np.sum(coverages_sr)/N, np.sum(accuracies_sr)/N, \n",
    "                                                            np.sum(supports_sr)/N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6e070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR STD: Coverage = 0.0007616642187342885 - Accuracy = 0.006653539381505247 - Support = 1.6071259533988718\n"
     ]
    }
   ],
   "source": [
    "print('SR STD: Coverage = {} - Accuracy = {} - Support = {}'.format(np.var(coverages_sr), np.var(accuracies_sr), \n",
    "                                                            np.var(supports_sr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54cfdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import utils\n",
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598b6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['meanradius',\n",
    " 'meantexture',\n",
    " 'meanperimeter',\n",
    " 'meanarea',\n",
    " 'meansmoothness',\n",
    " 'meancompactness',\n",
    " 'meanconcavity',\n",
    " 'meanconcavepoints',\n",
    " 'meansymmetry',\n",
    " 'meanfractaldimension',\n",
    " 'radiuserror',\n",
    " 'textureerror',\n",
    " 'perimetererror',\n",
    " 'areaerror',\n",
    " 'smoothnesserror',\n",
    " 'compactnesserror',\n",
    " 'concavityerror',\n",
    " 'concavepointserror',\n",
    " 'symmetryerror',\n",
    " 'fractaldimensionerror',\n",
    " 'worstradius',\n",
    " 'worsttexture',\n",
    " 'worstperimeter',\n",
    " 'worstarea',\n",
    " 'worstsmoothness',\n",
    " 'worstcompactness',\n",
    " 'worstconcavity',\n",
    " 'worstconcavepoints',\n",
    " 'worstsymmetry',\n",
    " 'worstfractaldimension']\n",
    "\n",
    "target_labels = ['True', 'False']\n",
    "\n",
    "    \n",
    "columns_names = feature_names\n",
    "columns_id = {}\n",
    "for i, col in enumerate(columns_names):\n",
    "    columns_id[col] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "997f24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    target_labels,\n",
    "    feature_names,\n",
    "    results.x_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab7173ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_results(explainer, x_test, x_train, predict, pi, columns_id):\n",
    "    N = x_train.shape[0]\n",
    "    d = x_train.shape[1]\n",
    "    rules = np.ones(shape=(N, d, 2))\n",
    "    rules[:, :, 0] = -1e+10\n",
    "    rules[:, :, 1] = 1e+10\n",
    "    \n",
    "    coverages = []\n",
    "    accuracies = []\n",
    "    supports = []\n",
    "    for idx in tqdm(range(N)):\n",
    "        exp = explainer.explain_instance(x_train[idx], predict, threshold=pi)\n",
    "        for r in exp.names():\n",
    "            r_split = r.split()\n",
    "            \n",
    "            if len(r_split) == 3:\n",
    "                col_id = columns_id[r_split[0]]\n",
    "                if r_split[1] == '<' or r_split[1] == '<=':\n",
    "                    rules[idx, col_id, 1] = r_split[2]\n",
    "                elif r_split[1] == '>' or r_split[1] == '>=':\n",
    "                    rules[idx, col_id, 0] = r_split[2]\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            elif len(r_split) == 5:\n",
    "                col_id = columns_id[r_split[2]]\n",
    "                rules[idx, col_id, 0] = r_split[0]\n",
    "                rules[idx, col_id, 0] = r_split[-1]\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "        x_train_in = np.prod([(x_train[:, s] <= rules[idx, s, 1]) * (x_train[:, s] > rules[idx, s, 0])\n",
    "                        for s in range(d)], axis=0).astype(bool)\n",
    "        x_in = np.prod([(x_test[:, s] <= rules[idx, s, 1]) * (x_test[:, s] > rules[idx, s, 0])\n",
    "                        for s in range(d)], axis=0).astype(bool)\n",
    "        \n",
    "        if np.sum(x_train_in) * np.sum(x_in) == 0:\n",
    "            continue\n",
    "            \n",
    "#         if np.abs(np.mean(x_train_in)-exp.coverage())>0.01:\n",
    "#             print(r)\n",
    "#             print(np.mean(x_train_in), exp.coverage())\n",
    "#             raise Warning('Inconsistency of the rules for this obs')\n",
    "            \n",
    "        \n",
    "        coverage = np.mean(x_in)\n",
    "        accuracy = np.mean(predict(x_test[x_in]) == predict(x_train[idx].reshape(1, -1)))\n",
    "        \n",
    "        coverages.append(coverage)\n",
    "        accuracies.append(accuracy)\n",
    "        supports.append(len(exp.names()))\n",
    "        \n",
    "    return coverages, accuracies, supports, rules\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████▎      | 381/455 [22:56<04:09,  3.37s/it]"
     ]
    }
   ],
   "source": [
    "coverages, accuracies, supports, rules = get_anchor_results(explainer, results.x_test, results.x_rules, \n",
    "                                                            results.acv_explainer.predict, pi=0.9, columns_id=columns_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = x_test.shape[0]\n",
    "# N = 500\n",
    "print('ANCHORS: Coverage = {} - Accuracy = {} - Support = {}'.format(np.sum(coverages)/N, np.sum(accuracies)/N, \n",
    "                                                            np.sum(supports)/N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ed9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = x_test.shape[0]\n",
    "# N = 500\n",
    "print('ANCHORS STD: Coverage = {} - Accuracy = {} - Support = {}'.format(np.var(coverages), np.var(accuracies), \n",
    "                                                            np.var(supports)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda978a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "sns.countplot(ax = ax[0], x=supports)\n",
    "sns.countplot(ax = ax[1], x=supports_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b791e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, count = np.unique(supports, return_counts=True)\n",
    "unique_sr, count_sr = np.unique(supports_sr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_support = dict(zip(unique, count))\n",
    "count_support_sr = dict(zip(unique_sr, count_sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb978ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_support_sr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
